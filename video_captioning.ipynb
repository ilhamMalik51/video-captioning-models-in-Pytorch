{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import Path,Vocabulary, utility, evaluator and datahandler module\n",
    "from config import Path\n",
    "from dictionary import Vocabulary\n",
    "from utils import Utils\n",
    "from evaluate import Evaluator\n",
    "from data import DataHandler\n",
    "\n",
    "#set seed for reproducibility\n",
    "utils = Utils()\n",
    "utils.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import configuration and model \n",
    "from config import ConfigMP\n",
    "from models.mean_pooling.model import MeanPooling\n",
    "\n",
    "\n",
    "from config import ConfigSALSTM\n",
    "from models.SA_LSTM.model import SALSTM\n",
    "\n",
    "#create Mean pooling object\n",
    "cfg = ConfigMP()\n",
    "# specifying the dataset in configuration object from {'msvd','msrvtt'}\n",
    "cfg.dataset = 'msrvtt'\n",
    "#creation of path object\n",
    "path = Path(cfg,os.getcwd())\n",
    "\n",
    "#Changing the hyperparameters in configuration object\n",
    "cfg.batch_size = 100 #training batch size\n",
    "cfg.n_layers = 2    # number of layers in decoder rnn\n",
    "cfg.decoder_type = 'lstm'  # from {'lstm','gru'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary creation or load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size :  29327\n"
     ]
    }
   ],
   "source": [
    "#Vocabulary object\n",
    "voc = Vocabulary(cfg)\n",
    "#If vocabulary is already saved or downloaded the saved file\n",
    "voc.load() #comment this if using vocabulary for the first time or with no saved file\n",
    "print('Vocabulary Size : ',voc.num_words) \n",
    "\n",
    "\n",
    "# # Uncomment this block if using vocabulary for the first time or if there is no saved file\n",
    "# text_dict = {}\n",
    "# voc = Vocabulary(cfg)\n",
    "# data_handler = DataHandler(cfg,path,voc)\n",
    "# import json\n",
    "# print(path.feature_file)\n",
    "# json.load(open(path.feature_file))\n",
    "# text_dict.update(data_handler.train_dict)\n",
    "# text_dict.update(data_handler.val_dict)\n",
    "# text_dict.update(data_handler.test_dict)\n",
    "# for k,v in text_dict.items():\n",
    "#     for anno in v:'\n",
    "#         voc.addSentence(anno)\n",
    "# voc.save()\n",
    "\n",
    "\n",
    "##Uncomment this block for filtering Rare Words from Dictionary\n",
    "# min_count = 2 #remove all words below count min_count\n",
    "# voc.trim(min_count=2)\n",
    "# print('Vocabulary Size : ',voc.num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloaders model and evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and dataloaders\n",
    "data_handler = DataHandler(cfg,path,voc)\n",
    "train_dset,val_dset,test_dset = data_handler.getDatasets()\n",
    "train_loader,val_loader,test_loader = data_handler.getDataloader(train_dset,val_dset,test_dset)\n",
    "\n",
    "#Model object\n",
    "model = MeanPooling(voc,cfg,path)\n",
    "#Evaluator object on test data\n",
    "test_evaluator = Evaluator(model,test_loader,path,cfg,data_handler.test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch -- > 50 Loss --> 5.024275640105086\n",
      "{'testlen': 17083, 'reflen': 19616, 'guess': [17083, 14093, 11103, 8113], 'correct': [11704, 5201, 2235, 480]}\n",
      "ratio: 0.8708707177813585\n",
      "{'Bleu_1': 0.5907105071688321, 'Bleu_2': 0.43354213369805633, 'Bleu_3': 0.31952249902913477, 'Bleu_4': 0.20197245965556046, 'METEOR': 0.18997056861640454, 'ROUGE_L': 0.4979413218606429, 'CIDEr': 0.09071018569955135}\n",
      "Epoch -- > 100 Loss --> 4.670244797724767\n",
      "{'testlen': 20704, 'reflen': 21822, 'guess': [20704, 17714, 14724, 11734], 'correct': [15758, 7718, 3443, 1205]}\n",
      "ratio: 0.948767299055955\n",
      "{'Bleu_1': 0.7210996267312337, 'Bleu_2': 0.5455893938392339, 'Bleu_3': 0.40401469516501004, 'Bleu_4': 0.283022016279368, 'METEOR': 0.23239376477749701, 'ROUGE_L': 0.5481253000758799, 'CIDEr': 0.21986267297381412}\n",
      "Epoch -- > 150 Loss --> 4.375256969156208\n",
      "{'testlen': 20305, 'reflen': 21482, 'guess': [20305, 17315, 14325, 11335], 'correct': [15972, 8102, 3653, 1322]}\n",
      "ratio: 0.9452099432082234\n",
      "{'Bleu_1': 0.7423043162637192, 'Bleu_2': 0.5725174173327918, 'Bleu_3': 0.4288637863441257, 'Bleu_4': 0.30524491219244887, 'METEOR': 0.23778082834823422, 'ROUGE_L': 0.5604802157708462, 'CIDEr': 0.2677504472482698}\n",
      "Epoch -- > 200 Loss --> 4.2458850413062095\n",
      "{'testlen': 20231, 'reflen': 21445, 'guess': [20231, 17241, 14251, 11261], 'correct': [15974, 8159, 3716, 1394]}\n",
      "ratio: 0.9433900676147846\n",
      "{'Bleu_1': 0.7435936214722997, 'Bleu_2': 0.575671502895314, 'Bleu_3': 0.4333509150193386, 'Bleu_4': 0.31209447015705455, 'METEOR': 0.2427754509420329, 'ROUGE_L': 0.5654496984564813, 'CIDEr': 0.2922663185673795}\n",
      "Epoch -- > 250 Loss --> 4.120713076181129\n",
      "{'testlen': 20227, 'reflen': 21469, 'guess': [20227, 17237, 14247, 11257], 'correct': [16119, 8341, 3832, 1474]}\n",
      "ratio: 0.9421491452791959\n",
      "{'Bleu_1': 0.7494447198073176, 'Bleu_2': 0.5840022408249678, 'Bleu_3': 0.4418633987985847, 'Bleu_4': 0.3210465237517311, 'METEOR': 0.24584118453897216, 'ROUGE_L': 0.5666379531299927, 'CIDEr': 0.3045687491488667}\n",
      "Epoch -- > 300 Loss --> 3.9967469028853833\n",
      "{'testlen': 20086, 'reflen': 21371, 'guess': [20086, 17096, 14106, 11116], 'correct': [16101, 8468, 3922, 1541]}\n",
      "ratio: 0.9398717888727275\n",
      "{'Bleu_1': 0.7519265888523847, 'Bleu_2': 0.5910699990844585, 'Bleu_3': 0.4499862026265895, 'Bleu_4': 0.3299262996039933, 'METEOR': 0.2482677480580764, 'ROUGE_L': 0.571968535447025, 'CIDEr': 0.3267415072004776}\n",
      "Epoch -- > 350 Loss --> 3.92683087628754\n",
      "{'testlen': 20721, 'reflen': 21829, 'guess': [20721, 17731, 14741, 11751], 'correct': [16558, 8732, 3996, 1572]}\n",
      "ratio: 0.9492418342571373\n",
      "{'Bleu_1': 0.7574856900328653, 'Bleu_2': 0.5946564004436903, 'Bleu_3': 0.4495755297157958, 'Bleu_4': 0.3276353425659584, 'METEOR': 0.24951286382008414, 'ROUGE_L': 0.5688339061591151, 'CIDEr': 0.32876694427776454}\n",
      "Epoch -- > 400 Loss --> 3.8317608417885283\n",
      "{'testlen': 20391, 'reflen': 21605, 'guess': [20391, 17401, 14411, 11421], 'correct': [16402, 8738, 4105, 1662]}\n",
      "ratio: 0.9438093034019466\n",
      "{'Bleu_1': 0.7578828791648776, 'Bleu_2': 0.5988138981539187, 'Bleu_3': 0.45826378018306674, 'Bleu_4': 0.3389255623124352, 'METEOR': 0.2522781200072049, 'ROUGE_L': 0.5781060231414057, 'CIDEr': 0.3426476925971906}\n",
      "Epoch -- > 450 Loss --> 3.7564391850280616\n",
      "{'testlen': 20340, 'reflen': 21590, 'guess': [20340, 17350, 14360, 11370], 'correct': [16434, 8827, 4198, 1732]}\n",
      "ratio: 0.9421028253820777\n",
      "{'Bleu_1': 0.7598058858490492, 'Bleu_2': 0.6029250252001555, 'Bleu_3': 0.46406090010923423, 'Bleu_4': 0.3459040676837692, 'METEOR': 0.2536483664496173, 'ROUGE_L': 0.5777581940161919, 'CIDEr': 0.35305861162181307}\n",
      "Epoch -- > 500 Loss --> 3.704782428572871\n",
      "{'testlen': 20443, 'reflen': 21647, 'guess': [20443, 17453, 14463, 11473], 'correct': [16542, 8964, 4287, 1761]}\n",
      "ratio: 0.9443802836420314\n",
      "{'Bleu_1': 0.7628961306666147, 'Bleu_2': 0.6077984635080131, 'Bleu_3': 0.4691144088011082, 'Bleu_4': 0.34961107036631367, 'METEOR': 0.2551301463907157, 'ROUGE_L': 0.5812583083471162, 'CIDEr': 0.3576735068533504}\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "cfg.encoder_lr = 1e-4\n",
    "cfg.decoder_lr = 1e-4\n",
    "cfg.teacher_forcing_ratio = 1.0\n",
    "model.update_hyperparameters(cfg)\n",
    "for e in range(1,511):\n",
    "    loss = model.train_epoch(train_loader,utils)\n",
    "    if e%50 == 0 :\n",
    "        print('Epoch -- >',e,'Loss -->',loss)\n",
    "        print(test_evaluator.evaluate(utils,model,e,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import configuration and model \n",
    "\n",
    "from config import ConfigSALSTM\n",
    "from models.SA_LSTM.model import SALSTM\n",
    "\n",
    "#create Mean pooling object\n",
    "cfg = ConfigSALSTM()\n",
    "# specifying the dataset in configuration object from {'msvd','msrvtt'}\n",
    "cfg.dataset = 'msvd'\n",
    "#creation of path object\n",
    "path = Path(cfg,os.getcwd())\n",
    "\n",
    "#Changing the hyperparameters in configuration object\n",
    "cfg.batch_size = 128 #training batch size\n",
    "cfg.n_layers = 2    # number of layers in decoder rnn\n",
    "cfg.decoder_type = 'lstm'  # from {'lstm','gru'}\n",
    "\n",
    "\n",
    "#Vocabulary object, \n",
    "voc = Vocabulary(cfg)\n",
    "#If vocabulary is already saved or downloaded the saved file\n",
    "voc.load() #comment this if using vocabulary for the first time or with no saved file\n",
    "print('Vocabulary Size : ',voc.num_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and dataloaders\n",
    "data_handler = DataHandler(cfg,path,voc)\n",
    "train_dset,val_dset,test_dset = data_handler.getDatasets()\n",
    "train_loader,val_loader,test_loader = data_handler.getDataloader(train_dset,val_dset,test_dset)\n",
    "\n",
    "#Model object\n",
    "model = SALSTM(voc,cfg,path)\n",
    "#Evaluator object on test data\n",
    "test_evaluator = Evaluator(model,test_loader,path,cfg,data_handler.test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "cfg.decoder_lr = 1e-5\n",
    "cfg.teacher_forcing_ratio = 1.0\n",
    "model.update_hyperparameters(cfg)\n",
    "for e in range(1,511):\n",
    "    loss = model.train_epoch(train_loader,utils)\n",
    "    if e%50 == 0 :\n",
    "        print('Epoch -- >',e,'Loss -->',loss)\n",
    "        print(test_evaluator.evaluate(utils,model,e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model,'SA_LSTM_lstm_2000.pt')\n",
    "#model = torch.load('msrvtt_lstm_mp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "features, target, mask, max_length,ides= dataiter.next()\n",
    "\n",
    "features.size(), target[:,5], mask[:,5],max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr,txt = model.GreedyDecoding(features.to(cfg.device))\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.target_tensor_to_caption(voc,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
